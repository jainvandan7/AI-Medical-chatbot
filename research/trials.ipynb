{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\medical-chatbot\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\medical-chatbot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from pdf file\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_pdf_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmedical-chatbot\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mData\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m, in \u001b[0;36mload_pdf_file\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_pdf_file\u001b[39m(data):\n\u001b[0;32m      3\u001b[0m     loader\u001b[38;5;241m=\u001b[39m DirectoryLoader(data,\n\u001b[0;32m      4\u001b[0m                             glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m                             loader_cls\u001b[38;5;241m=\u001b[39mPyPDFLoader)\n\u001b[1;32m----> 7\u001b[0m     documents\u001b[38;5;241m=\u001b[39m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:195\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[1;32m--> 195\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_load_file(i, p, pbar)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[0;32m    198\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:223\u001b[0m, in \u001b[0;36mDirectoryLoader._lazy_load_file\u001b[1;34m(self, item, path, pbar)\u001b[0m\n\u001b[0;32m    221\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_cls(\u001b[38;5;28mstr\u001b[39m(item), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_kwargs)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdoc \u001b[38;5;129;01min\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mlazy_load():\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m subdoc\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:307\u001b[0m, in \u001b[0;36mPyPDFLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     blob \u001b[38;5;241m=\u001b[39m Blob\u001b[38;5;241m.\u001b[39mfrom_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:396\u001b[0m, in \u001b[0;36mPyPDFParser.lazy_parse\u001b[1;34m(self, blob)\u001b[0m\n\u001b[0;32m    394\u001b[0m single_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_number, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf_reader\u001b[38;5;241m.\u001b[39mpages):\n\u001b[1;32m--> 396\u001b[0m     text_from_page \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_text_from_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m     images_from_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_images_from_page(page)\n\u001b[0;32m    398\u001b[0m     all_text \u001b[38;5;241m=\u001b[39m _merge_text_and_extras(\n\u001b[0;32m    399\u001b[0m         [images_from_page], text_from_page\n\u001b[0;32m    400\u001b[0m     )\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:378\u001b[0m, in \u001b[0;36mPyPDFParser.lazy_parse.<locals>._extract_text_from_page\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m page\u001b[38;5;241m.\u001b[39mextract_text()\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m page\u001b[38;5;241m.\u001b[39mextract_text(\n\u001b[0;32m    379\u001b[0m         extraction_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextraction_mode,\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextraction_kwargs,\n\u001b[0;32m    381\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\_page.py:2378\u001b[0m, in \u001b[0;36mPageObject.extract_text\u001b[1;34m(self, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text, extraction_mode, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orientations, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   2376\u001b[0m     orientations \u001b[38;5;241m=\u001b[39m (orientations,)\n\u001b[1;32m-> 2378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2381\u001b[0m \u001b[43m    \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONTENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2387\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\_page.py:2121\u001b[0m, in \u001b[0;36mPageObject._extract_text\u001b[1;34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[0m\n\u001b[0;32m   2119\u001b[0m xobj \u001b[38;5;241m=\u001b[39m resources_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/XObject\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xobj[operands[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Subtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Image\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m-> 2121\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_xform_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2129\u001b[0m     output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m   2130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visitor_text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\_page.py:2413\u001b[0m, in \u001b[0;36mPageObject.extract_xform_text\u001b[1;34m(self, xform, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[0m\n\u001b[0;32m   2389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_xform_text\u001b[39m(\n\u001b[0;32m   2390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2391\u001b[0m     xform: EncodedStreamObject,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2396\u001b[0m     visitor_text: Optional[Callable[[Any, Any, Any, Any, Any], \u001b[38;5;28;01mNone\u001b[39;00m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   2398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2399\u001b[0m \u001b[38;5;124;03m    Extract text from an XObject.\u001b[39;00m\n\u001b[0;32m   2400\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2411\u001b[0m \n\u001b[0;32m   2412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2416\u001b[0m \u001b[43m        \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\_page.py:1859\u001b[0m, in \u001b[0;36mPageObject._extract_text\u001b[1;34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[0m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Font\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resources_dict:\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m cast(DictionaryObject, resources_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Font\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m-> 1859\u001b[0m         cmaps[f] \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_char_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1860\u001b[0m cmap: Tuple[\n\u001b[0;32m   1861\u001b[0m     Union[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mstr\u001b[39m, Optional[DictionaryObject]\n\u001b[0;32m   1862\u001b[0m ] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1866\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1867\u001b[0m )  \u001b[38;5;66;03m# (encoding, CMAP, font resource name, font)\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\_cmap.py:33\u001b[0m, in \u001b[0;36mbuild_char_map\u001b[1;34m(font_name, space_width, obj)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_char_map\u001b[39m(\n\u001b[0;32m     18\u001b[0m     font_name: \u001b[38;5;28mstr\u001b[39m, space_width: \u001b[38;5;28mfloat\u001b[39m, obj: DictionaryObject\n\u001b[0;32m     19\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]], Dict[Any, Any], DictionaryObject]:\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    Determine information about a font.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     ft: DictionaryObject \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Resources\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Font\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfont_name\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     font_subtype, font_halfspace, font_encoding, font_map \u001b[38;5;241m=\u001b[39m build_char_map_from_dict(\n\u001b[0;32m     35\u001b[0m         space_width, ft\n\u001b[0;32m     36\u001b[0m     )\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m font_subtype, font_halfspace, font_encoding, font_map, ft\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\generic\\_data_structures.py:478\u001b[0m, in \u001b[0;36mDictionaryObject.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PdfObject:\n\u001b[1;32m--> 478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\generic\\_base.py:368\u001b[0m, in \u001b[0;36mIndirectObject.get_object\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_object\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdfObject\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\_reader.py:464\u001b[0m, in \u001b[0;36mPdfReader.get_object\u001b[1;34m(self, indirect_reference)\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PdfReadError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected loop with self reference for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindirect_reference\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_objects\u001b[38;5;241m.\u001b[39madd(current_object)\n\u001b[1;32m--> 464\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mread_object\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_objects\u001b[38;5;241m.\u001b[39mremove(current_object)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# override encryption is used for the /Encrypt dictionary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\generic\\_data_structures.py:1470\u001b[0m, in \u001b[0;36mread_object\u001b[1;34m(stream, pdf, forced_encoding)\u001b[0m\n\u001b[0;32m   1468\u001b[0m stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# reset to start\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peek \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDictionaryObject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_from_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforced_encoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_hex_string_from_stream(stream, forced_encoding)\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pypdf\\generic\\_data_structures.py:617\u001b[0m, in \u001b[0;36mDictionaryObject.read_from_stream\u001b[1;34m(stream, pdf, forced_encoding)\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m PdfReadError(msg)\n\u001b[0;32m    615\u001b[0m         logger_warning(msg, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m--> 617\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m s \u001b[38;5;241m=\u001b[39m read_non_whitespace(stream)\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtream\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extracted_data = load_pdf_file(data=r'c:\\medical-chatbot\\Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into text chunks \n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "       embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "       return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devya\\AppData\\Local\\Temp\\ipykernel_34536\\860081201.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "c:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
    "MISTRAL_API_KEY=os.environ.get('MISTRAL_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index medichatbot already exists\n",
      "✅ Pinecone index is ready!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve Pinecone API Key\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "MISTRAL_API_KEY_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "# Ensure API Key is loaded\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"PINECONE_API_KEY is missing! Check your .env file.\")\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Define the index name\n",
    "index_name = \"medichatbot\"\n",
    "\n",
    "# List existing indexes\n",
    "existing_indexes = pc.list_indexes().names()\n",
    "\n",
    "# Check if the index exists before creating it\n",
    "if index_name not in existing_indexes:\n",
    "    # Create index with serverless configuration\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # Matches all-MiniLM-L6-v2 embedding size\n",
    "        metric=\"cosine\",\n",
    "        spec={\n",
    "            \"serverless\": {\n",
    "                \"cloud\": \"aws\",\n",
    "                \"region\": \"us-east-1\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    print(f\"Creating new index: {index_name}\")\n",
    "else:\n",
    "    print(f\"Index {index_name} already exists\")\n",
    "\n",
    "print(\"✅ Pinecone index is ready!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pinecone API key successfully set in environment!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve Pinecone API Key\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"PINECONE_API_KEY is missing! Check your .env file.\")\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY\n",
    "\n",
    "print(\"✅ Pinecone API key successfully set in environment!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings successfully stored in Pinecone!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Ensure text_chunks is defined\n",
    "if 'text_chunks' not in locals():\n",
    "    raise ValueError(\"text_chunks is not defined. Run the previous cells first.\")\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Upload text chunks to Pinecone\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "print(\"✅ Embeddings successfully stored in Pinecone!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devya\\AppData\\Local\\Temp\\ipykernel_28644\\1999658530.py:14: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully connected to Pinecone index!\n",
      "Test query returned 1 document(s)\n"
     ]
    }
   ],
   "source": [
    "# 1. First, import all required libraries\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 2. Load environment variables (make sure your .env file has PINECONE_API_KEY)\n",
    "load_dotenv()\n",
    "\n",
    "# 3. Define your index name (MUST match the name you used when creating the index)\n",
    "index_name = \"medichatbot\"  # ← Change this if you used a different name\n",
    "\n",
    "# 4. Initialize the embeddings model (MUST match what you used previously)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 5. Now connect to your existing Pinecone index\n",
    "try:\n",
    "    docsearch = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    print(\"✅ Successfully connected to Pinecone index!\")\n",
    "    \n",
    "    # Test the connection with a sample query\n",
    "    test_results = docsearch.similarity_search(\"What is diabetes?\", k=1)\n",
    "    print(f\"Test query returned {len(test_results)} document(s)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error connecting to Pinecone: {str(e)}\")\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Verify index name is correct (check Pinecone dashboard)\")\n",
    "    print(\"2. Ensure you used the same embeddings model when creating the index\")\n",
    "    print(\"3. Check your .env file has the correct PINECONE_API_KEY\")\n",
    "    print(\"4. Make sure you ran all previous cells to set up the index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devya\\AppData\\Local\\Temp\\ipykernel_24472\\1293320530.py:14: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully connected to Pinecone index!\n",
      "✅ Retriever successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devya\\AppData\\Local\\Temp\\ipykernel_24472\\1293320530.py:34: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(test_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever test returned 3 documents:\n",
      "\n",
      "Document 1:\n",
      "begin to fall. A person with diabetes mellitus either does\n",
      "not make enough insulin, or makes insulin that does not\n",
      "work properly. The result is blood sugar that remains\n",
      "high, a condition called hyperg...\n",
      "\n",
      "Document 2:\n",
      "Resources\n",
      "BOOKS\n",
      "Berkow, Robert, ed. The Merck Manual of Medical Informa-\n",
      "tion: Home Edition. Whitehouse Station, NJ: Merck &\n",
      "Co., Inc., 1997.\n",
      "KEY TERMS\n",
      "Aplastic —Exhibiting incomplete or faulty devel-...\n",
      "\n",
      "Document 3:\n",
      "their diet and from their body tissues. Insulin is made by\n",
      "the pancreas and affects the outer membrane of cells,\n",
      "making it easy for glucose to move from the blood into\n",
      "the cells. When insulin is activ...\n"
     ]
    }
   ],
   "source": [
    "# 1. First, import all required libraries\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 2. Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# 3. Define your index name (must match existing index)\n",
    "index_name = \"medichatbot\"  # ← Change if you used different name\n",
    "\n",
    "# 4. Initialize embeddings model (must match what you used before)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 5. Connect to Pinecone index\n",
    "try:\n",
    "    # Initialize the vector store\n",
    "    docsearch = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    print(\"✅ Successfully connected to Pinecone index!\")\n",
    "    \n",
    "    # Now create the retriever\n",
    "    retriever = docsearch.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3}\n",
    "    )\n",
    "    print(\"✅ Retriever successfully created!\")\n",
    "    \n",
    "    # Test the retriever\n",
    "    test_query = \"What is diabetes?\"\n",
    "    results = retriever.get_relevant_documents(test_query)\n",
    "    print(f\"Retriever test returned {len(results)} documents:\")\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"\\nDocument {i}:\")\n",
    "        print(doc.page_content[:200] + \"...\")  # Print first 200 chars\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {str(e)}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Verify index exists in Pinecone dashboard\")\n",
    "    print(\"2. Check index name spelling\")\n",
    "    print(\"3. Ensure embeddings model matches index dimension\")\n",
    "    print(\"4. Confirm .env has correct PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral API Key works! {'id': '649053a5d76846baba603c74a630e55c', 'object': 'chat.completion', 'created': 1743408573, 'model': 'mistral-medium', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'tool_calls': None, 'content': 'Of course! How can'}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 17, 'total_tokens': 23, 'completion_tokens': 6}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Set Mistral API key\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")  # Or manually set it as a string\n",
    "\n",
    "# Define API request\n",
    "url = \"https://api.mistral.ai/v1/chat/completions\"  # Correct endpoint\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {MISTRAL_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Chat-based message format (similar to OpenAI's chat models)\n",
    "data = {\n",
    "    \"model\": \"mistral-medium\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Test\"}\n",
    "    ],\n",
    "    \"max_tokens\": 5\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response_json = response.json()\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"Mistral API Key works!\", response_json)\n",
    "    else:\n",
    "        print(\"Mistral API Error:\", response_json)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_openai\\llms\\base.py:189\u001b[0m, in \u001b[0;36mBaseOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient:\n\u001b[0;32m    188\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msync_specific)\u001b[38;5;241m.\u001b[39mcompletions  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n\u001b[0;32m    191\u001b[0m     async_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_async_client}\n",
      "File \u001b[1;32mc:\\Users\\devya\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\openai\\_client.py:114\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    112\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0.4, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieval context to answer\"\n",
    "    \"The question. If you dont know the answer, say that you\"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer conscise, yet detailed enough.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "      (\"system\", system_prompt),\n",
    "      (\"human\", \"{input}\"),\n",
    "  ]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral API Key works! Of course! How can\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Set Mistral API key\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")  # Or manually set it as a string\n",
    "\n",
    "# Define API request\n",
    "url = \"https://api.mistral.ai/v1/chat/completions\"  # Correct endpoint\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {MISTRAL_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Use messages instead of prompt (chat-based format)\n",
    "data = {\n",
    "    \"model\": \"mistral-medium\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Test\"}\n",
    "    ],\n",
    "    \"max_tokens\": 5\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response_json = response.json()\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"Mistral API Key works!\", response_json[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "    else:\n",
    "        print(\"Mistral API Error:\", response_json)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devya\\AppData\\Local\\Temp\\ipykernel_24472\\2221185600.py:5: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedding_model = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# ✅ Create a new FAISS vector store (if missing)\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "vector_store = FAISS.from_texts([\"Sample text\"], embedding_model)\n",
    "vector_store.save_local(\"my_vector_db\")  # Save the new index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devya\\AppData\\Local\\Temp\\ipykernel_24472\\3123051799.py:20: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  HuggingFaceEmbeddings(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acne is a skin condition that occurs when your hair follicles become plugged with oil and dead skin cells. It often causes whiteheads, blackheads or pimples, and usually appears on the face, forehead, chest, upper back and shoulders. Acne is most common among teenagers, though it affects people of all ages. Effective treatments are available, but acne can be persistent. The pimples and bumps heal slowly, and when one begins to go away, others seem to crop up.\n",
      "\n",
      "Answer:\n",
      "\n",
      "Acne is a skin condition that happens when hair follicles are clogged with oil and dead skin cells, leading to whiteheads, blackheads, or pimples. It commonly occurs on the face, forehead, chest, upper back, and shoulders and is prevalent among teenagers, although it can affect people of all ages. While treatments are available, acne can be a persistent issue with new pimples appearing as old ones heal.\n"
     ]
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI  # ✅ Correct import\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "\n",
    "# Set Mistral API key\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "# ✅ Use ChatMistralAI instead of MistralChat\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-medium\",\n",
    "    temperature=0.5,\n",
    "    api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "# Example FAISS retriever\n",
    "vector_store = FAISS.load_local(\n",
    "    \"my_vector_db\", \n",
    "    HuggingFaceEmbeddings(), \n",
    "    allow_dangerous_deserialization=True  # ✅ Fix: Allow safe deserialization\n",
    ")\n",
    "\n",
    "\n",
    "# Create RAG Chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "# Test query\n",
    "response = rag_chain.invoke({\"query\": \"What is Acne?\"})  # ✅ Fix: Use \"query\" instead of \"input\"\n",
    "print(response[\"result\"])  # ✅ Change \"answer\" to \"result\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rag_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_chain\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is malaria?\u001b[39m\u001b[38;5;124m\"\u001b[39m})  \u001b[38;5;66;03m# ✅ Fix: Use \"query\" instead of \"input\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# ✅ Change \"answer\" to \"result\"\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rag_chain' is not defined"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"query\": \"What is malaria?\"})  # ✅ Fix: Use \"query\" instead of \"input\"\n",
    "print(response[\"result\"])  # ✅ Change \"answer\" to \"result\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
